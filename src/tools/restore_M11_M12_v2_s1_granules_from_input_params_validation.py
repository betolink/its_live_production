#!/usr/bin/env python
"""
Restore M11 and M12 values of the Sentinel-1 V2 data based on input parameters as generated by autoRIFT code base.
This script handles V2 Sentinel-1 granules that were originally corrected but lost their M11 and M12 values when
storing corrected granule to the file (encoding parameters were omitted).

Reference table, as provided by Joe, contains the following information per each row:
reference        S1A_IW_SLC__1SDV_20170203T162106_20170203T162132_015121_018B9A_1380
secondary        S1A_IW_SLC__1SDV_20170215T162105_20170215T162133_015296_019127_6E1E
v2_s3_bucket     its-live-data
v2_s3_key        velocity_image_pair/sentinel1/v02/N00E020/S1A_IW_SLC__1SDV_20170203T162106_20170203T162132_015121_018B9A_1380_X_S1A_IW_SLC__1SDV_20170215T162105_20170215T162133_015296_019127_6E1E_G0120V02_P099.nc
status           SUCCEEDED
to_correct       False
cor_s3_bucket    hyp3-its-live-contentbucket-s10lg85g5sp4
job_id           a851f0b5-9ae2-43fe-b81d-344eeae67b79

where the correction tifs for a particular file will all be in s3://[cor_s3_bucket]/[job_id]/

ATTN: This script should run from AWS EC2 instance to have fast access to the S3
bucket. It takes 2 seconds to upload the file to the S3 bucket from EC2 instance
vs. 1.5 minutes to upload the file from laptop to the S3 bucket.

Authors: Masha Liukis, Alex Gardner, Joe Kennedy
"""
import argparse
import boto3
from datetime import datetime
from botocore.exceptions import ClientError
import dask
from dask.diagnostics import ProgressBar
import json
import logging
import numpy as np
import os
import pandas as pd
import s3fs
import xarray as xr

from itscube_types import DataVars, Coords, Output
from mission_info import Encoding


class RestoreM11M12Values:
    """
    Restore corrected M11 and M12 values for existing V2 Sentinel1 granules, copy corrected granule and corresponding PNG files
    to the target location in AWS S3 bucket.
    """
    NC_ENGINE = 'h5netcdf'

    # Reference file that stores M11/M12 values to restore: have to divide by date_dt when restoring
    CONVERSION_MATRICES_NC_FILE = 'conversion_matrices.nc'

    # S3 bucket with granules
    BUCKET = 'its-live-data'

    # Source S3 bucket directory
    SOURCE_DIR = 'velocity_image_pair/sentinel1/v02'

    GRANULE_LIST_FILE = 'used_granules.json'

    # Target S3 bucket directory
    TARGET_DIR = None

    # Local directory to store corrected granules before copying them to the S3 bucket
    LOCAL_DIR = 'sandbox-correct-S1'

    # Number of granules to process in parallel
    CHUNK_SIZE = 100

    # Number of Dask workers for parallel processing
    DASK_WORKERS = 8

    DRYRUN = False

    def __init__(self, granule_table: str):
        """
        Initialize object.

        Inputs:
        =======
        granule_table: File that stores information for granule correction.
        """
        self.s3 = s3fs.S3FileSystem()

        # Use another s3fs object to read reference TIF data
        self.s3_ref = s3fs.S3FileSystem()

        self.table = pd.read_parquet(granule_table)

        logging.info(f"Total number of granules to correct: {len(self.table)}")

        # Store listings of original and target granules to the files in case we want to store/load granules lists
        # for subsequent runs
        existing_granules_file = os.path.join(
            RestoreM11M12Values.BUCKET,
            RestoreM11M12Values.SOURCE_DIR,
            RestoreM11M12Values.GRANULE_LIST_FILE
        )

        self.all_original_granules = []

        # Read a list of original granules from the target S3 bucket
        with self.s3.open(existing_granules_file, 'r') as ins3file:
            self.all_original_granules = json.load(ins3file)
            logging.info(f"Loaded {len(self.all_original_granules)} original granules from '{existing_granules_file}'")

    def __call__(self, start_index: int = 0, stop_index: int = 0):
        """
        Restore M11 and M12 from provided input parameters files and copy restored granule along with corresponding PNG files
        to the target location in S3 bucket.
        """
        num_to_fix = len(self.table)

        if stop_index > 0:
            num_to_fix = stop_index

        num_to_fix -= start_index

        # For debugging only
        # num_to_fix = 3

        start = start_index
        logging.info(f"{num_to_fix} granules to correct...")

        if num_to_fix <= 0:
            logging.info("Nothing to fix, exiting.")
            return

        if not os.path.exists(RestoreM11M12Values.LOCAL_DIR):
            os.mkdir(RestoreM11M12Values.LOCAL_DIR)

        while num_to_fix > 0:
            num_tasks = RestoreM11M12Values.CHUNK_SIZE if num_to_fix > RestoreM11M12Values.CHUNK_SIZE else num_to_fix

            logging.info(f"Starting tasks {start}:{start+num_tasks}")

            tasks = [
                dask.delayed(RestoreM11M12Values.correct)(
                    # each['v2_s3_bucket'],
                    each['v2_s3_key'],
                    # os.path.basename(each['v2_s3_key']),
                    each['cor_s3_bucket'],
                    each['job_id'],
                    self.s3,
                    self.s3_ref,
                    self.all_original_granules
                ) for _, each in self.table.iloc[start:start+num_tasks].iterrows()
            ]
            results = None

            with ProgressBar():
                # Display progress bar
                results = dask.compute(
                    tasks,
                    scheduler="processes",
                    num_workers=RestoreM11M12Values.DASK_WORKERS
                )

            for each_result in results[0]:
                logging.info("-->".join(each_result))

            num_to_fix -= num_tasks
            start += num_tasks

    @staticmethod
    def find_granule_path(granule_basename: str, all_original_granules: list):
        """Given granule filename find its full path in s3://its-live-data bucket.

        Args:
            granule_basename (str): Granule filename.

        Returns:
            Original granule S3 path that corresponds to the target URL.
        """
        found_granule = [each for each in all_original_granules if os.path.basename(each) == granule_basename]
        if len(found_granule) == 0:
            raise RuntimeError(f'Could not find original granule that corresponds to {granule_basename}')

        if len(found_granule) > 1:
            # Should never happen, just to be sure
            raise RuntimeError(f'More than one granule found that corresponds to {granule_basename}: {found_granule}')

        return found_granule[0]

    @staticmethod
    def correct(
        granule_path: str,
        ref_bucket: str,
        ref_dir: str,
        s3: s3fs.S3FileSystem,
        s3_ref: s3fs.S3FileSystem,
        all_original_granules: list
    ):
        """
        Correct S1 data for the granule residing in S3 bucket. Copy corrected granule along with corresponding PNG files
        to the new S3 location.

        Inputs:
        =======
        bucket: S3 bucket holding granule for correction.
        granule_path: Granule path within S3 bucket.
        ref_bucket: S3 bucket with reference data for correction.
        ref_dir: S3 directory path that holds reference data for correction.
        s3: s3fs.S3FileSystem object to access original ITS_LIVE granules for correction.
        s3_ref: s3fs.S3FileSystem object to access data for correction.
        all_original_granules: List of all V2 S1 granules as stored in S3 bucket (on user end).
        """
        msgs = [f'Processing {granule_path}']
        granule_basename = os.path.basename(granule_path)

        # Read granule to correct
        ds = None

        # Find granule to correct in the list of existing granules
        granule_s3_path = RestoreM11M12Values.find_granule_path(granule_basename, all_original_granules)

        # Read the granule for correction in
        with s3.open(granule_s3_path, mode='rb') as fhandle:
            with xr.open_dataset(fhandle, engine=RestoreM11M12Values.NC_ENGINE) as ds:
                ds = ds.load()

        # Get the date separation in days from the granule to divide M11 and M12 by
        date_dt = ds.img_pair_info.attrs['date_dt']

        # Read M11 and M12 from reference files

        # Initialize mask to correspond to the granule's X/Y extends to crop reference file to
        mask = None

        cropped_m11_m12 = None
        invalid_v_mask = np.isnan(ds.v)

        s3_m11_m12_file = os.path.join(ref_bucket, ref_dir, RestoreM11M12Values.CONVERSION_MATRICES_NC_FILE)

        msgs.append(f'Reading: {s3_m11_m12_file}')
        with s3.open(s3_m11_m12_file, mode='rb') as fhandle:
            with xr.open_dataset(fhandle, engine=RestoreM11M12Values.NC_ENGINE) as m11_m12_ds:
                m11_m12_ds = m11_m12_ds.load()

                # Crop dataset to granule's X/Y ranges
                mask_x = (m11_m12_ds.x >= ds.x.min().item()) & (m11_m12_ds.x <= ds.x.max().item())
                mask_y = (m11_m12_ds.y >= ds.y.min().item()) & (m11_m12_ds.y <= ds.y.max().item())
                mask = (mask_x & mask_y)

                cropped_m11_m12 = m11_m12_ds.where(mask, drop=True)

                # Apply valid v mask of the granule to M11 and M12 values (to have the same coverage)
                nan_cropped_m11 = cropped_m11_m12.M11.where(~invalid_v_mask, other=np.nan)
                ds[DataVars.M11] = nan_cropped_m11 * date_dt

                nan_cropped_m12 = cropped_m11_m12.M12.where(~invalid_v_mask, other=np.nan)
                ds[DataVars.M12] = nan_cropped_m12 * date_dt

                # Restore M11 and M12 values based input parameter file values / date_dt
                for each_var in [DataVars.M11, DataVars.M12]:
                    if Output.SCALE_FACTOR in ds[each_var].encoding:
                        # Remove both compression encoding attributes if present
                        del ds[each_var].encoding[Output.SCALE_FACTOR]
                        del ds[each_var].encoding[Output.ADD_OFFSET]

        # Add date when granule was updated
        ds.attrs['date_updated'] = datetime.now().strftime('%d-%b-%Y %H:%M:%S')

        # Save to local file

        # Set chunking for 2D data variables
        dims = ds.dims
        num_x = dims[Coords.X]
        num_y = dims[Coords.Y]

        # Compute chunking like AutoRIFT does:
        # https://github.com/ASFHyP3/hyp3-autorift/blob/develop/hyp3_autorift/vend/netcdf_output.py#L410-L411
        chunk_lines = np.min([np.ceil(8192/num_y)*128, num_y])
        two_dim_chunks_settings = (chunk_lines, num_x)

        granule_encoding = Encoding.SENTINEL1.copy()

        for each_var, each_var_settings in granule_encoding.items():
            if each_var_settings[Output.FILL_VALUE_ATTR] is not None:
                each_var_settings[Output.CHUNKSIZES_ATTR] = two_dim_chunks_settings

        # Set compression encoding attributes for M11 and M12: have to recompute since we divide original values by date_dt
        # Do like hyp3 does: https://github.com/ASFHyP3/hyp3-autorift/blob/develop/src/hyp3_autorift/s1_isce2.py#L186
        y1 = -50
        y2 = 50

        for each_var in [DataVars.M11, DataVars.M12]:
            # Recompute compression encoding attributes for restored M11/M12 values
            x1 = np.nanmin(ds[each_var])
            x2 = np.nanmax(ds[each_var])

            C = [(y2 - y1) / (x2 - x1), y1 - x1 * (y2 - y1) / (x2 - x1)]

            granule_encoding[each_var][Output.SCALE_FACTOR] = np.float32(1 / C[0])
            granule_encoding[each_var][Output.ADD_OFFSET] = np.float32(-C[1] / C[0])

            no_data_mask = np.isnan(ds[each_var])
            ds[each_var].data[no_data_mask] = DataVars.MISSING_VALUE * np.float32(1 / C[0]) + np.float32(-C[1] / C[0])

        fixed_file = os.path.join(RestoreM11M12Values.LOCAL_DIR, granule_basename)

        # Save to local file
        ds.to_netcdf(fixed_file, engine='h5netcdf', encoding=granule_encoding)

        # Upload corrected granule to the bucket - format sub-directory based on new cropped values
        if not RestoreM11M12Values.DRYRUN:
            s3_client = boto3.client('s3')
            try:
                # Upload granule to the target directory in the bucket
                target = granule_s3_path.replace(RestoreM11M12Values.SOURCE_DIR, RestoreM11M12Values.TARGET_DIR)

                msgs.append(f"Uploading to {target}")
                s3_client.upload_file(fixed_file, RestoreM11M12Values.BUCKET, target)

                # msgs.append(f"Removing local {fixed_file}")
                os.unlink(fixed_file)

                # There are corresponding browse and thumbprint images to transfer
                bucket = boto3.resource('s3').Bucket(RestoreM11M12Values.BUCKET)

                for target_ext in ['.png', '_thumb.png']:
                    target_key = target.replace('.nc', target_ext)

                    # Path to original PNG file in the S3 bucket - just copy to new location in s3
                    source_key = granule_s3_path.replace('.nc', target_ext)

                    source_dict = {
                        'Bucket': RestoreM11M12Values.BUCKET,
                        'Key': source_key
                    }

                    bucket.copy(source_dict, target_key)
                    msgs.append(f'Copying {target_ext} to s3')

            except ClientError as exc:
                msgs.append(f"ERROR: {exc}")

        return msgs


def main():
    parser = argparse.ArgumentParser(
        description=__doc__.split('\n')[1],
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        '--read_granule_list',
        action='store_true',
        help=f'Read granule file list from {RestoreM11M12Values.GRANULE_LIST_FILE} stored in the target S3 bucket only (to avoid time consuming glob). '
    )
    parser.add_argument(
        '-c', '--chunk_size',
        type=int,
        default=100,
        help='Number of granules to process in parallel [%(default)d]'
    )
    parser.add_argument(
        '-t', '--target_bucket_dir',
        type=str,
        default='velocity_image_pair/sentinel1-restoredM-test/',
        help='AWS S3 bucket and directory to store corrected granules'
    )
    parser.add_argument(
        '-l', '--local_dir',
        type=str,
        default='sandbox-sentinel1',
        help='Directory to store fixed granules before uploading them to the S3 bucket'
    )
    parser.add_argument(
        '-w', '--dask_workers',
        type=int,
        default=8,
        help='Number of Dask parallel workers [%(default)d]'
    )
    parser.add_argument(
        '-s', '--start_granule',
        type=int,
        default=0,
        help='Index for the start granule to process (if previous processing terminated) [%(default)d]'
    )
    parser.add_argument(
        '-e', '--stop_granule',
        type=int,
        default=0,
        help='Index for the last granule to process (if splitting processing across multiple EC2s) [%(default)d]'
    )
    parser.add_argument(
        '--granule_table',
        # default='fix_s1_v2_granules/correction_table/sentinel-1-correction-files.parquet',
        default='sentinel-1-correction-files.parquet',
        help='Table that provides the reference data for the granules to correct [%(default)s]'
    )
    parser.add_argument(
        '--dryrun',
        action='store_true',
        help='Dry run, do not actually copy any data to AWS S3 bucket'
    )

    args = parser.parse_args()
    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s',
                        datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.INFO)

    logging.info(f"Args: {args}")

    RestoreM11M12Values.CHUNK_SIZE = args.chunk_size
    RestoreM11M12Values.DASK_WORKERS = args.dask_workers
    RestoreM11M12Values.TARGET_DIR = args.target_bucket_dir
    RestoreM11M12Values.LOCAL_DIR = args.local_dir
    RestoreM11M12Values.DRYRUN = args.dryrun

    process_granules = RestoreM11M12Values(args.granule_table)
    process_granules(args.start_granule, args.stop_granule)


if __name__ == '__main__':
    main()

    logging.info("Done.")
